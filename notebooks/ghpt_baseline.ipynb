{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samgregson/GHPT-colab-experiments/blob/main/Grasshopper_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS2KaXUa6ULz"
      },
      "source": [
        "# Setup\n",
        "install openai and setup API key\n",
        "\n",
        "This notebook works both in a Colab environment and on local machine\n",
        "\n",
        "Colab:\n",
        "- API key must be saved in Colab sectrets as OPENAI_API_KEY\n",
        "\n",
        "Local:\n",
        "- API key must be defined in the .env file (refer to example.env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "IN_COLAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jy5pEkKl0OyR"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    %pip install openai\n",
        "    %pip install requests\n",
        "\n",
        "if IN_COLAB:\n",
        "    import os\n",
        "    from google.colab import userdata\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "    os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
        "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "    os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "    os.environ[\"LANGCHAIN_PROJECT\"] = \"GHPT_Instructor\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### load files into Colab and install package\n",
        "\n",
        "NOTE: you may need to refresh your Colab files directory to see changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    # remove the existing directory\n",
        "    import shutil\n",
        "    shutil.rmtree('/content/GHPT-experiments/', ignore_errors=True)\n",
        "    %git clone \"https://github.com/samgregson/GHPT-experiments\"\n",
        "    %pip install -e /content/GHPT-experiments/\n",
        "    # add the modules to the search path\n",
        "    import site\n",
        "    site.main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the correct SSL certificates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not IN_COLAB:\n",
        "    import os\n",
        "    import ssl\n",
        "    context = ssl.create_default_context(cafile=os.environ.get(\"REQUESTS_CA_BUNDLE\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the correct SSL certificates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not IN_COLAB:\n",
        "    import os\n",
        "    import ssl\n",
        "    context = ssl.create_default_context(cafile=os.environ.get(\"REQUESTS_CA_BUNDLE\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCORn5u76b3n"
      },
      "source": [
        "### OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_KuOYMzj61v3"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from langsmith.wrappers import wrap_openai\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "# Custom wrap for VSCode, needs to be the first wrap!\n",
        "if not IN_COLAB:\n",
        "    from patch_openai.patch_openai import patch_openai\n",
        "    client = patch_openai(client)\n",
        "\n",
        "# Wrap the OpenAI client with LangSmith\n",
        "client = wrap_openai(client)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### test connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8HXy6lMA4dq",
        "outputId": "7ce53fd2-ea76-48c8-f018-597f36604dc0"
      },
      "outputs": [],
      "source": [
        "# model: str = \"gpt-3.5-turbo-1106\"\n",
        "# temperature: float = 0\n",
        "\n",
        "# prompt=\"say this is a test\"\n",
        "# system_prompt=\"\"\n",
        "\n",
        "# completion = call_openai(prompt=prompt, system_prompt=system_prompt, model=model, temperature=temperature)\n",
        "# result = completion.choices[0].message.content\n",
        "# print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47XPmW1mPiTw"
      },
      "source": [
        "# GHPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb2mp36c73Yi"
      },
      "source": [
        "### Import prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from prompts.generate_script import system_prompt, prompt_template\n",
        "\n",
        "# replace all { with {{ and } with }} to escape the curly braces\n",
        "prompt_template = prompt_template.replace(\"{\",\"{{\").replace(\"}\",\"}}\").replace(\"{{QUESTION}}\",\"{QUESTION}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBGAjqv1780t"
      },
      "source": [
        "## Baseline Call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EiYlQ5mIzBf3"
      },
      "outputs": [],
      "source": [
        "from langsmith import traceable\n",
        "\n",
        "# create the openai api call function\n",
        "@traceable\n",
        "def call_openai(prompt: str, system_prompt: str = \"\", model: str = \"gpt-3.5-turbo-1106\", temperature: float = 0):\n",
        "    if system_prompt == \"\":\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    else:\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        temperature=temperature,\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    return completion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wht7UJWg0jca",
        "outputId": "2cba7402-be8b-45b8-86cc-932bb7c13bd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "\t\"Advice\": \"Remember to set the radius of the sphere using a number slider\",\n",
            "\t\"Additions\": [\n",
            "\t\t{\n",
            "\t\t\t\"Name\": \"Sphere\",\n",
            "\t\t\t\"Id\": 1\n",
            "\t\t},\n",
            "\t\t{\n",
            "\t\t\t\"Name\": \"Number Slider\",\n",
            "\t\t\t\"Id\": 2,\n",
            "\t\t\t\"value\": \"0..10..50\"\n",
            "\t\t}\n",
            "\t],\n",
            "\t\"Connections\": [\n",
            "\t\t{\n",
            "\t\t\t\"To\": {\n",
            "\t\t\t\t\"Id\": 1,\n",
            "\t\t\t\t\"ParameterName\": \"Radius\"\n",
            "\t\t\t},\n",
            "\t\t\t\"From\": {\n",
            "\t\t\t\t\"Id\": 2,\n",
            "\t\t\t\t\"ParameterName\": \"Number\"\n",
            "\t\t\t}\n",
            "\t\t}\n",
            "\t]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "model: str = \"gpt-3.5-turbo-1106\"\n",
        "# model: str = \"gpt-3.5-turbo\"\n",
        "# model = \"gpt-4\"\n",
        "temperature: float = 0\n",
        "\n",
        "prompt=system_prompt + prompt_template.format(QUESTION=\"create a sphere\")\n",
        "\n",
        "completion = call_openai(prompt=prompt, system_prompt=\"\", model=model, temperature=temperature)\n",
        "result = completion.choices[0].message\n",
        "print(result.content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMfW6HNeJ1iT+VDWPPQb17l",
      "collapsed_sections": [
        "KS2KaXUa6ULz"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
