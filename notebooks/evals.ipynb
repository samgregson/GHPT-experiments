{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pK47INbGNzRu"
   },
   "source": [
    "# Setup\n",
    "install openai and setup API key\n",
    "\n",
    "This notebook works both in a Colab environment and on local machine\n",
    "\n",
    "Colab:\n",
    "- API key must be saved in Colab sectrets as OPENAI_API_KEY\n",
    "\n",
    "Local:\n",
    "- API key must be defined in the .env file (refer to example.env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stLZ3XLXNzR0",
    "outputId": "d2c816d2-074b-4b7a-99a5-80ef0b3f832d"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "IN_COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMU7kkFtNzR3",
    "outputId": "356426c7-7e7b-429f-cc92-d89abd5a0492"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    %pip install openai\n",
    "    %pip install requests\n",
    "    %pip install -U instructor\n",
    "    %pip install anthropic\n",
    "    %pip install langsmith\n",
    "    import os\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = \"GHPT_Instructor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8iZwkZ0NzR4"
   },
   "source": [
    "### load files into Colab and install package\n",
    "\n",
    "NOTE: you may need to refresh your Colab files directory to see changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5e7iGjINzR5",
    "outputId": "5e7e7526-ec61-4eea-9bd1-e76eb795b14b"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    # remove the existing directory\n",
    "    import shutil\n",
    "    shutil.rmtree('/content/GHPT-experiments/', ignore_errors=True)\n",
    "    !git clone \"https://github.com/samgregson/GHPT-experiments\"\n",
    "    %pip install -e /content/GHPT-experiments/\n",
    "    # add the modules to the search path\n",
    "    import site\n",
    "    site.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vMnJqsGNzR6"
   },
   "source": [
    "Load the correct SSL certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFuEefs6NzR6"
   },
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    import ssl\n",
    "    load_dotenv()\n",
    "    context = ssl.create_default_context(cafile=os.environ.get(\"REQUESTS_CA_BUNDLE\"))\n",
    "    print(os.environ.get(\"REQUESTS_CA_BUNDLE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tWMXfOmNzR7"
   },
   "source": [
    "test SSL certificate, this should return `<Response [200]>` if not try restarting the Jupyter kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N00HsopjNzR8"
   },
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    import requests\n",
    "    # requests.get(\"https://fastapi-production-e161.up.railway.app/docs\")\n",
    "    requests.get(\"https://api.smith.langchain.com/docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6w7Qs_HNzR9"
   },
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tMhYWuRNzR-"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI, AsyncOpenAI\n",
    "from langsmith.wrappers import wrap_openai\n",
    "\n",
    "client = AsyncOpenAI()\n",
    "\n",
    "# Custom wrap for VSCode, needs to be the first wrap!\n",
    "if not IN_COLAB:\n",
    "    from patch_openai.patch_openai import patch_openai\n",
    "    client = patch_openai(client)\n",
    "\n",
    "# Wrap the OpenAI client with LangSmith\n",
    "client = wrap_openai(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMnIL6MrNzR-"
   },
   "outputs": [],
   "source": [
    "import instructor\n",
    "\n",
    "client_instructor = instructor.from_openai(client, mode=instructor.Mode.TOOLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.components import get_components_with_embeddings\n",
    "\n",
    "get_components_with_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-CCXJn8NzR_"
   },
   "source": [
    "# Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Umpq8csN9Eo"
   },
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from validation_set import inputs, outputs\n",
    "\n",
    "ls_client = Client()\n",
    "\n",
    "# Define dataset: these are your test cases\n",
    "dataset_name = \"Simple Example Dataset\"\n",
    "if len(list(ls_client.list_datasets(dataset_name=dataset_name))) == 0:\n",
    "    dataset = ls_client.create_dataset(dataset_name)\n",
    "    ls_client.create_examples(\n",
    "        inputs=[\n",
    "            {\"question\": input} for input in inputs\n",
    "        ],\n",
    "        dataset_id=dataset.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7StLGR5NzR_"
   },
   "outputs": [],
   "source": [
    "from pipeline.pipeline import run_pipeline\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "index = 1\n",
    "\n",
    "async def run_all():\n",
    "    tasks = []\n",
    "    for i, input in enumerate(inputs):\n",
    "        if i < index: continue # start index\n",
    "        if i > index: break # finish index\n",
    "        tasks.append(run_pipeline(client=client_instructor, user_prompt=input))\n",
    "    return await asyncio.gather(*tasks)\n",
    "\n",
    "all_output = await run_all()\n",
    "\n",
    "print(all_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# experiment_results = evaluate(\n",
    "#     lambda inputs: asyncio.run(\n",
    "#         run_pipeline(client=client_instructor, user_prompt=inputs[\"user_prompt\"])\n",
    "#     ),\n",
    "#     data=ls_client.list_examples(example_ids=['e6564fb7-e626-4d25-ac9e-48d5219b6c1f']),\n",
    "#     # data=dataset_name,\n",
    "#     evaluators=[],\n",
    "#     experiment_prefix=\"simple-experiment\",\n",
    "#     metadata={\n",
    "#       \"description\": \"'instructor' baseline\"\n",
    "#     },\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
