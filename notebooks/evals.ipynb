{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pK47INbGNzRu"
   },
   "source": [
    "# Setup\n",
    "install openai and setup API key\n",
    "\n",
    "This notebook works both in a Colab environment and on local machine\n",
    "\n",
    "Colab:\n",
    "- API key must be saved in Colab sectrets as OPENAI_API_KEY\n",
    "\n",
    "Local:\n",
    "- API key must be defined in the .env file (refer to example.env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stLZ3XLXNzR0",
    "outputId": "d2c816d2-074b-4b7a-99a5-80ef0b3f832d"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "IN_COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMU7kkFtNzR3",
    "outputId": "356426c7-7e7b-429f-cc92-d89abd5a0492"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    %pip install openai\n",
    "    %pip install requests\n",
    "    %pip install -U instructor\n",
    "    %pip install anthropic\n",
    "    %pip install langsmith\n",
    "    import os\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = \"GHPT_Instructor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8iZwkZ0NzR4"
   },
   "source": [
    "### load files into Colab and install package\n",
    "\n",
    "NOTE: you may need to refresh your Colab files directory to see changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5e7iGjINzR5",
    "outputId": "5e7e7526-ec61-4eea-9bd1-e76eb795b14b"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    # remove the existing directory\n",
    "    import shutil\n",
    "    shutil.rmtree('/content/GHPT-experiments/', ignore_errors=True)\n",
    "    !git clone \"https://github.com/samgregson/GHPT-experiments\"\n",
    "    %pip install -e /content/GHPT-experiments/\n",
    "    # add the modules to the search path\n",
    "    import site\n",
    "    site.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vMnJqsGNzR6"
   },
   "source": [
    "Load the correct SSL certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFuEefs6NzR6"
   },
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    import ssl\n",
    "    load_dotenv()\n",
    "    context = ssl.create_default_context(cafile=os.environ.get(\"REQUESTS_CA_BUNDLE\"))\n",
    "    print(os.environ.get(\"REQUESTS_CA_BUNDLE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tWMXfOmNzR7"
   },
   "source": [
    "test SSL certificate, this should return `<Response [200]>` if not try restarting the Jupyter kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N00HsopjNzR8"
   },
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    import requests\n",
    "    requests.get(\"https://api.smith.langchain.com/docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6w7Qs_HNzR9"
   },
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tMhYWuRNzR-"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI, AsyncOpenAI\n",
    "from langsmith.wrappers import wrap_openai\n",
    "\n",
    "client = AsyncOpenAI()\n",
    "\n",
    "# Custom wrap for VSCode, needs to be the first wrap!\n",
    "if not IN_COLAB:\n",
    "    from patch_openai.patch_openai import patch_openai\n",
    "    client = patch_openai(client)\n",
    "\n",
    "# Wrap the OpenAI client with LangSmith\n",
    "client = wrap_openai(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMnIL6MrNzR-"
   },
   "outputs": [],
   "source": [
    "import instructor\n",
    "\n",
    "client_instructor = instructor.patch(client, mode=instructor.Mode.JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-CCXJn8NzR_"
   },
   "source": [
    "# Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a__qAsCWNzR_"
   },
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    \"Create a cylinder with a radius of 5 and a height of 10.\",\n",
    "    \"Generate a spiral with 10 turns and a radius of 2.\",\n",
    "    \"Create a rectangular grid of 5 by 5 points with a spacing of 10 in the x and y directions.\",\n",
    "    \"Generate a sphere with a radius of 10 at the origin.\",\n",
    "    \"Create a series of 10 circles with radii increasing by 1 for each subsequent circle.\",\n",
    "    \"Generate a 3D grid of 5x5x5 spheres with a spacing of 10 in the x, y, and z directions.\",\n",
    "    \"Create a line from the origin to the point (10,10,10).\",\n",
    "    \"Generate a series of 10 squares with side lengths increasing by 2 for each subsequent square.\",\n",
    "    \"Create a cone with a base radius of 5 and a height of 10.\",\n",
    "    \"Generate a torus with a tube radius of 2 and a path radius of 5.\",\n",
    "    \"Create a triangular grid of 5 by 5 points with a spacing of 10 in the x and y directions.\",\n",
    "    \"Generate a series of 10 rectangles with lengths and widths increasing by 2 for each subsequent rectangle.\",\n",
    "    \"Create a pyramid with a base side length of 5 and a height of 10.\",\n",
    "    \"Generate a series of 10 lines with lengths increasing by 2 for each subsequent line.\",\n",
    "    \"Create a hexagonal grid of 5 by 5 points with a spacing of 10 in the x and y directions.\",\n",
    "    \"Generate a series of 10 hexagons with side lengths increasing by 1 for each subsequent hexagon.\",\n",
    "    \"Create a 3D grid of 5x5x5 cubes with a spacing of 10 in the x, y, and z directions. The size of the cubes should be determined by each cube's proximity to a random point on the grid such that at distance 0 the cube has dimensions 0 and at distance 1 the cube has dimensions 1.\",\n",
    "    \"Generate a series of 10 cylinders with radii increasing by 1 and heights increasing by 2 for each subsequent cylinder.\",\n",
    "    \"Create a series of 10 cones with base radii increasing by 1 and heights increasing by 2 for each subsequent cone.\",\n",
    "    \"Generate a series of 10 pyramids with base side lengths increasing by 1 and heights increasing by 2 for each subsequent pyramid.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Umpq8csN9Eo"
   },
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "ls_client = Client()\n",
    "\n",
    "# Define dataset: these are your test cases\n",
    "dataset_name = \"Simple Example Dataset\"\n",
    "if len(list(ls_client.list_datasets(dataset_name=dataset_name))) == 0:\n",
    "    dataset = ls_client.create_dataset(dataset_name)\n",
    "    ls_client.create_examples(\n",
    "        inputs=[\n",
    "            {\"question\": input} for input in inputs\n",
    "        ],\n",
    "        dataset_id=dataset.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7StLGR5NzR_"
   },
   "outputs": [],
   "source": [
    "from pipeline.pipeline import run_pipeline\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def run_all():\n",
    "    tasks = []\n",
    "    for i, input in enumerate(inputs):\n",
    "        if i < 16: continue # start index\n",
    "        if i > 16: break # finish index\n",
    "        tasks.append(run_pipeline(client=client_instructor, user_prompt=input))\n",
    "    return await asyncio.gather(*tasks)\n",
    "\n",
    "all_output = await run_all()\n",
    "\n",
    "print(all_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# experiment_results = evaluate(\n",
    "#     lambda inputs: asyncio.run(\n",
    "#         run_pipeline(client=client_instructor, user_prompt=inputs[\"user_prompt\"])\n",
    "#     ),\n",
    "#     data=ls_client.list_examples(example_ids=['e6564fb7-e626-4d25-ac9e-48d5219b6c1f']),\n",
    "#     # data=dataset_name,\n",
    "#     evaluators=[],\n",
    "#     experiment_prefix=\"simple-experiment\",\n",
    "#     metadata={\n",
    "#       \"description\": \"'instructor' baseline\"\n",
    "#     },\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
